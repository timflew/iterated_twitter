{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# I'm positive! :)\n",
    "\n",
    "I'm planning on doing a high-risk, high-reward (ideally low-investment) project on how people process emoticons in Tweets. Many studies have used emoticons to label Tweets for supervised(-ish) classifier training, a procedure known as [\"Distant Supervision\"](http://web.stanford.edu/~jurafsky/mintz.pdf). In its basic implementation:\n",
    "\n",
    "1. A corpus of Tweets is collected\n",
    "2. Tweets containing positive ( :) ) and negative emoticons ( :( ) are identified and labeled as positive or negative\n",
    "3. The emoticons are then stripped from those Tweets and the classifier is trained on them\n",
    "4. The classifier is applied to a testing set.\n",
    "\n",
    "And this works pretty well and has the perk of not requiring you to get a bunch of people on mturk to label Tweets by hand! \n",
    "\n",
    "The project I'm planning is going to spice this up by adding some Psychology into the mix--How do people remember Tweets if we randomly add positive and negative emoticons to them? If this technique works, it could have some useful implications for classification tasks in general. There are many situations where there are not clear labeled examples such as situations in which emoticons are considered inappropriate (e.g., deaths) or where the baserate of category expression is low ([inferring political preferences based on Tweets is hindered by most Republicans and Democrats who aren't elected officials posting very little political content](https://www.aaai.org/ocs/index.php/ICWSM/ICWSM13/paper/viewFile/6128/6347))\n",
    "\n",
    "But first, I want to establish how well a rudimentary classifier can do using 1) Tweets that have the correct labels (a reasonable upper bound) 2) Using neutral Tweets that we've randomly given positive and negative emoticons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Various utility packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "# Weird unicode error processing some of the tweets\n",
    "import re\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Machine learning and string processing packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import tweet_preprocess\n",
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "# 1. Setting up models and data processing functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Naive Bayes classifier\n",
    "\n",
    "For this project, I'm going to initially use a simple Naive Bayes model that uses the binary presence or absence of a word. While tf-idf (text frequency-inverse document frequency) is useful in many situations, given that Tweets are short and meaningful words are unlikely to repeat, we shouldn't get much more information using tf-idf.\n",
    "\n",
    "Concretely, given training and testing data, the code below trains a classifier based on whether the 100 top words were present or not (binary) and then cross-validates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nb_classifier(tweet_train, tweet_test, label_train, label_test,K):\n",
    "\t# Run Naive Bayes classifier on binary presence\n",
    "\n",
    "\t## Vectorize training words\n",
    "\ttrain_count_vec=CountVectorizer(binary=True)\n",
    "\ttrain_count_words=train_count_vec.fit_transform(tweet_train)\n",
    "\ttest_count_words=train_count_vec.transform(tweet_test)\n",
    "\ttrain_feat_names=train_count_vec.get_feature_names()\n",
    "\n",
    "\t# Reduce feature space to K best features\n",
    "\tch2 = SelectKBest(chi2, k=K)\n",
    "\tX_train = ch2.fit_transform(train_count_words, label_train)\n",
    "\tX_test = ch2.transform(test_count_words)\n",
    "\n",
    "\tfeature_names=train_count_vec.get_feature_names()\n",
    "\tk_feature_inds=[]\n",
    "\tfor ii in ch2.get_support(indices=True): \n",
    "\t\tk_feature_inds.append(feature_names[ii])\n",
    "\n",
    "\t# NB model\n",
    "\tnb_class=BernoulliNB()\n",
    "\tnb_class.fit(X_train,label_train)\n",
    "\n",
    "\tprint 'Training accuracy'\n",
    "\ttrain_acc=nb_class.score(X_train,label_train)\n",
    "\tprint train_acc\n",
    "\n",
    "\tprint 'Testing accuracy'\n",
    "\ttest_acc=nb_class.score(X_test,label_test)\n",
    "\tprint test_acc\n",
    "\n",
    "\treturn train_count_vec,k_feature_inds,test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all tweets and return the each Tweet's text and label (0 for negative, 1 for positive)\n",
    "\n",
    "This code loads our [corpus](http://www.cs.york.ac.uk/semeval-2013/task2/). These Tweets have all been rated by hand. I already ran the code that downloads all the tweets from Twitter and stores them into a tsv (tweet-b-actual.tsv in the file below).\n",
    "\n",
    "There's also some NLP steps I added in here to remove stopwords (e.g., the, a) and to stem the words (e.g., justice->just, justify->just)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading processed tweets...\n",
      "Load complete\n"
     ]
    }
   ],
   "source": [
    "## Load tweets and positive (1), negative (0) labels\n",
    "def load_tweets(fname):\n",
    "\t# Load tweets text\n",
    "\n",
    "\tif not os.path.exists(fname):\n",
    "\t\tprint 'Processing tweets...'\n",
    "\n",
    "\t\t# Identify stopwords to remove\n",
    "\t\tsw=stopwords.words('english')\n",
    "\n",
    "\t\t# create stemmer to stem words\n",
    "\t\tstemmer=SnowballStemmer(\"english\")\n",
    "\n",
    "\t\tfold_name='semval'\n",
    "\t\t#file_name='tweet-a.tsv' # a is context rating\n",
    "\t\tfile_name='tweet-b-actual.tsv' # b is message rating\n",
    "\t\tfull_name=os.path.join(fold_name,file_name)\n",
    "\t\ttweet_text_temp,tweet_label_temp=tweet_preprocess.load_tweets(full_name)\n",
    "\n",
    "\t\ttweet_text=[]\n",
    "\t\ttweet_label=[]\n",
    "\t\tfor ttt,tlt in zip(tweet_text_temp,tweet_label_temp):\n",
    "\n",
    "\t\t\tif tlt=='positive' or tlt=='negative':\n",
    "\t\t\t\t# Store string minus stopwords\n",
    "\t\t\t\tttt=ttt.lower()\n",
    "\t\t\t\tfor s in sw:\n",
    "\t\t\t\t\tttt=re.sub('(?<![a-z])'+s+'(?![a-z])',' ',ttt)\n",
    "\t\t\t\t\t#ttt=str.replace(str(ttt),'\\s'+s+'\\s','') # Remove stopwords\n",
    "\n",
    "\t\t\t\t# stem words\n",
    "\t\t\t\tttt_split=str.split(str(ttt),' ')\n",
    "\t\t\t\tnew_ttt=''\n",
    "\t\t\t\tfor it in ttt_split:\n",
    "\t\t\t\t\tnew_ttt=new_ttt+' '+stemmer.stem(it)\n",
    "\n",
    "\t\t\t\ttweet_text.append(new_ttt)\n",
    "\n",
    "\t\t\t\t# labels\n",
    "\t\t\t\tif tlt=='positive':\n",
    "\t\t\t\t\ttweet_label.append(1)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\ttweet_label.append(0)\n",
    "\t\twith open(fname, 'w') as f:\n",
    "\t\t\tpickle.dump([tweet_text,tweet_label], f)\n",
    "\telse:\n",
    "\t\tprint 'Loading processed tweets...'\n",
    "\t\twith open(fname) as f:\n",
    "\t\t\ttweet_text,tweet_label = pickle.load(f)\n",
    "        print 'Load complete'\n",
    "\n",
    "\n",
    "\treturn tweet_text,tweet_label\n",
    "\n",
    "fname='semval/loaded_tweets.pickle'\n",
    "tweet_text_raw,tweet_label_raw=load_tweets(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typical for Twitter data, we have a bias towards positive Tweets (people generally don't like to post their complaints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Baserate of positive Tweets\n",
      "0.732074263764\n"
     ]
    }
   ],
   "source": [
    "prob_positive=np.mean(np.array(tweet_label_raw))\n",
    "\n",
    "print '\\nBaserate of positive Tweets'\n",
    "print prob_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Baserate of positive Tweets\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "def equal_size_samples(tweet_text,tweet_label):\n",
    "    neg_ind=np.array(tweet_label)==0\n",
    "    num_neg=np.sum(neg_ind)\n",
    "\n",
    "    tweet_neg=[tweet_text[i] for i in np.where(neg_ind)[0]]\n",
    "    \n",
    "    pos_ind=np.array(tweet_label)==1\n",
    "    num_pos=np.sum(pos_ind)\n",
    "    tweet_pos=[tweet_text[i] for i in np.where(pos_ind)[0]]\n",
    "    \n",
    "    num_samp=np.min([num_neg,num_pos])\n",
    "    tweet_neg_samp=np.random.choice(tweet_neg,size=num_samp,replace=False)\n",
    "    tweet_pos_samp=np.random.choice(tweet_pos,size=num_samp,replace=False)\n",
    "  \n",
    "    new_tweet_text=[]\n",
    "    for tw in tweet_neg_samp: new_tweet_text.append(tw)\n",
    "    for tw in tweet_pos_samp: new_tweet_text.append(tw)        \n",
    "\n",
    "    new_tweet_label=[0]*num_samp+[1]*num_samp\n",
    "    return new_tweet_text,new_tweet_label\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "tweet_text,tweet_label=equal_size_samples(tweet_text_raw,tweet_label_raw)  \n",
    "\n",
    "prob_positive=np.mean(np.array(tweet_label))\n",
    "print '\\nBaserate of positive Tweets'\n",
    "print prob_positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How well can we do with correctly labeled training examples?\n",
    "\n",
    "Let's run our classifier on the correctly labeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using labeled sentiment tweets to predict sentiment tweets\n",
      "\n",
      "1 Best Features\n",
      "Training accuracy\n",
      "0.542372881356\n",
      "Testing accuracy\n",
      "0.533453887884\n",
      "\n",
      "5 Best Features\n",
      "Training accuracy\n",
      "0.619982158787\n",
      "Testing accuracy\n",
      "0.598553345389\n",
      "\n",
      "10 Best Features\n",
      "Training accuracy\n",
      "0.655664585192\n",
      "Testing accuracy\n",
      "0.654611211573\n",
      "\n",
      "100 Best Features\n",
      "Training accuracy\n",
      "0.800178412132\n",
      "Testing accuracy\n",
      "0.669077757685\n",
      "\n",
      "1000 Best Features\n",
      "Training accuracy\n",
      "0.942908117752\n",
      "Testing accuracy\n",
      "0.660036166365\n",
      "\n",
      "Best K: 100\n",
      "Test accuracy: 0.669077757685\n"
     ]
    }
   ],
   "source": [
    "num_samp=len(tweet_text)\n",
    "tweet_text=tweet_text[0:num_samp]\n",
    "tweet_label=tweet_label[0:num_samp]\t\n",
    "\n",
    "tweet_train, tweet_test, label_train, label_test = train_test_split(tweet_text, tweet_label, \\\n",
    "                                                                    test_size=0.33, random_state=42)\n",
    "\n",
    "print '\\nUsing labeled sentiment tweets to predict sentiment tweets'\n",
    "num_K=[1,5,10,100,500,1000]\n",
    "best_k=0\n",
    "best_acc=0\n",
    "best_classifier=None\n",
    "best_feature_names=None\n",
    "for K in num_K:\n",
    "    print '\\n'+str(K)+' Best Features'\n",
    "    labeled_classifier,labeled_feature_names,labeled_acc= \\\n",
    "        nb_classifier(tweet_train, tweet_test, label_train, label_test,K)\n",
    "    if labeled_acc>best_acc: best_k=K;best_acc=labeled_acc; \\\n",
    "        best_classifier=labeled_classifier;best_feature_names=labeled_feature_names\n",
    "\n",
    "print '\\nBest K: '+str(best_k)\n",
    "print 'Test accuracy: '+str(best_acc)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a small improvement from baseline (~.5) using a pretty stupid model. In the future, I'll want to add bigrams and other features, but I seem to have at least the basic tools for answering my questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "K=100 best words\n",
      "[u'10th', u'1st', u'8pm', u'amaz', u'award', u'awesom', u'bad', u'band', u'biggest', u'birthday', u'bit', u'bless', u'boehner', u'bro', u'cancel', u'cast', u'come', u'concert', u'day', u'dead', u'deal', u'delay', u'demitra', u'didn', u'die', u'dont', u'enjoy', u'excit', u'fail', u'fb', u'feb', u'feel', u'final', u'forward', u'free', u'fuck', u'fun', u'good', u'great', u'happen', u'happi', u'harvey', u'hey', u'homecom', u'honor', u'hope', u'http', u'instagr', u'instead', u'iv', u'japan', u'justinbieb', u'kill', u'kinda', u'know', u'like', u'll', u'loss', u'love', u'may', u'mon', u'movie', u'need', u'news', u'next', u'novemb', u'november', u'obama', u'pavol', u'perfect', u'pj', u'proud', u'put', u'right', u'riot', u'road', u'rock', u'rugbi', u'sad', u'saturday', u'school', u'see', u'serious', u'shit', u'show', u'side', u'sorri', u'stop', u'stupid', u'super', u'thank', u'ticket', u'tri', u'twat', u'use', u'weekend', u'win', u'window', u'without', u'wors']\n"
     ]
    }
   ],
   "source": [
    "print '\\n'\n",
    "print 'K='+str(best_k) +' best words'\n",
    "print best_feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a lot of the words seem to make sense too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How about with incorrectly labeled neutral examples?\n",
    "\n",
    "And for a null null baseline, let's try to do this classification with neutral Tweets that we assign labels to randomly. Our key manipulation is going to be trying to use people's interpretation of emoticons to get some sentiment-word signal out of these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load neutral tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_neutral_tweets(fname,prob_positive):\n",
    "\t# Load tweets text\n",
    "\n",
    "\tif not os.path.exists(fname):\n",
    "\t\tprint 'Processing tweets...'\n",
    "\n",
    "\t\t# Identify stopwords to remove\n",
    "\t\tsw=stopwords.words('english')\n",
    "\n",
    "\t\t# create stemmer to stem words\n",
    "\t\tstemmer=SnowballStemmer(\"english\")\n",
    "\n",
    "\t\tfold_name='semval'\n",
    "\t\t#file_name='tweet-a.tsv' # a is context rating\n",
    "\t\tfile_name='tweet-b-actual.tsv' # b is message rating\n",
    "\t\tfull_name=os.path.join(fold_name,file_name)\n",
    "\t\ttweet_text_temp,tweet_label_temp=tweet_preprocess.load_tweets(full_name)\n",
    "\n",
    "\t\ttweet_text=[]\n",
    "\t\ttweet_label=[]\n",
    "\t\tfor ttt,tlt in zip(tweet_text_temp,tweet_label_temp):\n",
    "\n",
    "\t\t\tif (not tlt=='positive') and (not tlt=='negative'):\n",
    "\t\t\t\t# Store string minus stopwords\n",
    "\t\t\t\tttt=ttt.lower()\n",
    "\t\t\t\tfor s in sw:\n",
    "\t\t\t\t\tttt=re.sub('(?<![a-z])'+s+'(?![a-z])',' ',ttt)\n",
    "\t\t\t\t\t#ttt=str.replace(str(ttt),'\\s'+s+'\\s','') # Remove stopwords\n",
    "\n",
    "\t\t\t\t# stem words\n",
    "\t\t\t\tttt_split=str.split(str(ttt),' ')\n",
    "\t\t\t\tnew_ttt=''\n",
    "\t\t\t\tfor it in ttt_split:\n",
    "\t\t\t\t\tnew_ttt=new_ttt+' '+stemmer.stem(it)\n",
    "\n",
    "\t\t\t\ttweet_text.append(new_ttt)\n",
    "\n",
    "\t\t\t\t# labels\n",
    "\t\t\t\tis_pos=random.random()<prob_positive\n",
    "\t\t\t\tif is_pos:\n",
    "\t\t\t\t\ttweet_label.append(1)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\ttweet_label.append(0)\n",
    "\t\twith open(fname, 'w') as f:\n",
    "\t\t\tpickle.dump([tweet_text,tweet_label], f)\n",
    "\telse:\n",
    "\t\tprint 'Loading processed tweets...'\n",
    "\t\twith open(fname) as f:\n",
    "\t\t\ttweet_text,tweet_label = pickle.load(f)\n",
    "\n",
    "\n",
    "\treturn tweet_text,tweet_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading processed tweets...\n",
      "\n",
      "Using neutral tweets to predict sentiment tweets\n",
      "\n",
      "1 Best Features\n",
      "Training accuracy\n",
      "0.740088105727\n",
      "Testing accuracy\n",
      "0.497287522604\n",
      "\n",
      "5 Best Features\n",
      "Training accuracy\n",
      "0.748409202154\n",
      "Testing accuracy\n",
      "0.499095840868\n",
      "\n",
      "10 Best Features\n",
      "Training accuracy\n",
      "0.754772393539\n",
      "Testing accuracy\n",
      "0.499095840868\n",
      "\n",
      "100 Best Features\n",
      "Training accuracy\n",
      "0.817914831131\n",
      "Testing accuracy\n",
      "0.48643761302\n",
      "\n",
      "500 Best Features\n",
      "Training accuracy\n",
      "0.84140969163\n",
      "Testing accuracy\n",
      "0.493670886076\n",
      "\n",
      "1000 Best Features\n",
      "Training accuracy\n",
      "0.844836025453\n",
      "Testing accuracy\n",
      "0.490054249548\n",
      "\n",
      "Best K: 5\n",
      "Test accuracy: 0.499095840868\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fname='semval/loaded_neutral_tweets.pickle'\n",
    "neutral_tweet_text,neutral_tweet_label=load_neutral_tweets(fname,.5)\n",
    "\n",
    "neutral_tweet_train, neutral_tweet_test, neutral_label_train, neutral_label_test = \\\n",
    "    train_test_split(neutral_tweet_text, neutral_tweet_label, test_size=0.33, random_state=42)\n",
    "\n",
    "print '\\nUsing neutral tweets to predict sentiment tweets'\n",
    "num_K=[1,5,10,100,500,1000]\n",
    "best_n_k=0\n",
    "best_n_acc=0\n",
    "best_n_classifier=None\n",
    "best_n_feature_names=None\n",
    "for K in num_K:\n",
    "    print '\\n'+str(K)+' Best Features'\n",
    "    neutral_classifier,neutral_feature_names,neutral_acc= \\\n",
    "        nb_classifier(neutral_tweet_train, tweet_test, neutral_label_train, label_test,K)\n",
    "    if neutral_acc>best_n_acc: best_n_k=K;best_n_acc=neutral_acc; \\\n",
    "        best_n_classifier=neutral_classifier;best_n_feature_n_names=neutral_feature_names\n",
    "\n",
    "print '\\nBest K: '+str(best_n_k)\n",
    "print 'Test accuracy: '+str(best_n_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "And as we would expect, no signal--The model performs at chance on the test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interim Summary\n",
    "\n",
    "Using a classifier trained on Tweets sentiment labeled by hand, we were able to classify Tweets as positive or negative. Neutral Tweets that we randomly assigned sentiments did not improve predictive power. And now comes the challenging part. Let's see if we can make some lemonade out of this by adding some emoticons and having people remember the Tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
